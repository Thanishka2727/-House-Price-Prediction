{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt49BqKmOX/MHV4ITBy113",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thanishka2727/-House-Price-Prediction/blob/main/House_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jUpByEgYtYV",
        "outputId": "42ceecd9-4842-4a86-fde9-341880a7517f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  MedHouseVal  \n",
            "0    -122.23        4.526  \n",
            "1    -122.22        3.585  \n",
            "2    -122.24        3.521  \n",
            "3    -122.25        3.413  \n",
            "4    -122.25        3.422  \n",
            "Training the model...\n",
            "\n",
            "Initial Model Performance:\n",
            "Mean Squared Error: 0.26\n",
            "R² Score: 0.8053\n",
            "\n",
            "Starting hyperparameter tuning...\n",
            "\n",
            "Best Model Performance:\n",
            "Best Model Mean Squared Error: 0.25\n",
            "Best Model R² Score: 0.8063\n",
            "Best Parameters: {'model__n_estimators': 200, 'model__min_samples_split': 2, 'model__max_depth': None}\n",
            "\n",
            "Model saved as house_price_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "df = data.frame\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset Head:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Define features and target variable\n",
        "X = df.drop(columns=['MedHouseVal'])  # Features\n",
        "y = df['MedHouseVal']  # Target variable (Median House Value)\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Identify numerical columns (No categorical columns in this dataset)\n",
        "numerical_cols = X_train.columns\n",
        "\n",
        "# Step 5: Data Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_cols)\n",
        "])\n",
        "\n",
        "# Step 6: Define the model (Random Forest Regressor)\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Step 7: Create a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Step 8: Train the model\n",
        "print(\"Training the model...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Step 9: Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Step 10: Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nInitial Model Performance:\")\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R² Score: {r2:.4f}')\n",
        "\n",
        "# Step 11: Hyperparameter tuning using RandomizedSearchCV\n",
        "print(\"\\nStarting hyperparameter tuning...\")\n",
        "param_dist = {\n",
        "    'model__n_estimators': [100, 200],  # Number of trees in the forest\n",
        "    'model__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
        "    'model__min_samples_split': [2, 5, 10]  # Minimum samples required to split a node\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV with fewer iterations and parallel processing\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_dist,\n",
        "    n_iter=5,  # Number of parameter settings sampled\n",
        "    cv=3,  # Number of cross-validation folds\n",
        "    scoring='r2',  # Evaluation metric\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 12: Get the best model and evaluate it\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "mse_best = mean_squared_error(y_test, y_pred_best)\n",
        "r2_best = r2_score(y_test, y_pred_best)\n",
        "\n",
        "print(\"\\nBest Model Performance:\")\n",
        "print(f'Best Model Mean Squared Error: {mse_best:.2f}')\n",
        "print(f'Best Model R² Score: {r2_best:.4f}')\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "\n",
        "# Step 13: Save the trained model\n",
        "joblib.dump(best_model, \"house_price_model.pkl\")\n",
        "print(\"\\nModel saved as house_price_model.pkl\")"
      ]
    }
  ]
}